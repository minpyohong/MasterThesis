{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,precision_score , recall_score , confusion_matrix , f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from ast import literal_eval\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020U1 = eucl_data\n",
    "data_2020U1.append(cosine_data)\n",
    "\n",
    "data_2020U1['period'] = 202011 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020D1 = eucl_data\n",
    "data_2020D1.append(cosine_data)\n",
    "\n",
    "data_2020D1['period'] = 202021 # 2020년의 down 2 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U1 = eucl_data\n",
    "data_2017U1.append(cosine_data)\n",
    "\n",
    "data_2017U1['period'] = 201711 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U2 = eucl_data\n",
    "data_2017U2.append(cosine_data)\n",
    "\n",
    "data_2017U2['period'] = 201712 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D1 = eucl_data\n",
    "data_2018D1.append(cosine_data)\n",
    "\n",
    "data_2018D1['period'] = 201821 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_complement1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_complement1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018C1 = eucl_data\n",
    "data_2018C1.append(cosine_data)\n",
    "\n",
    "data_2018C1['period'] = 201831 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D2 = eucl_data\n",
    "data_2018D2.append(cosine_data)\n",
    "\n",
    "data_2018D2['period'] = 201822 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U1 = eucl_data\n",
    "data_2019U1.append(cosine_data)\n",
    "\n",
    "data_2019U1['period'] = 201911 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U2 = eucl_data\n",
    "data_2019U2.append(cosine_data)\n",
    "\n",
    "data_2019U2['period'] = 201912 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U3 = eucl_data\n",
    "data_2019U3.append(cosine_data)\n",
    "\n",
    "data_2019U3['period'] = 201913 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D1 = eucl_data\n",
    "data_2019D1.append(cosine_data)\n",
    "\n",
    "data_2019D1['period'] = 201921 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D2 = eucl_data\n",
    "data_2019D2.append(cosine_data)\n",
    "\n",
    "data_2019D2['period'] = 201922 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D3 = eucl_data\n",
    "data_2019D3.append(cosine_data)\n",
    "\n",
    "data_2019D3['period'] = 201923 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down4_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down4_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D4 = eucl_data\n",
    "data_2019D4.append(cosine_data)\n",
    "\n",
    "data_2019D4['period'] = 201924 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.concat([data_2020U1,data_2020D1,data_2017U1,data_2018D1,data_2018C1,data_2018D2,data_2019U1,data_2019U2,data_2019U3,data_2019D1,data_2019D2,data_2019D3,data_2019D4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['period'] = pd.to_numeric(data_train['period'], errors='coerce')\n",
    "data_train['category'] = pd.to_numeric(data_train['category'], errors='coerce')\n",
    "data_train['label'] = pd.to_numeric(data_train['label'], errors='coerce')\n",
    "data_train['Silhouette'] = pd.to_numeric(data_train['Silhouette'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "y_data_df = data_train['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))\n",
    "print(len(x_data_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : np.mean(np.array([i for i in x],dtype=float)) )\n",
    "# x_data_df['raw_data'] = pd.to_numeric(x_data_df['raw_data'],errors='coerce')\n",
    "\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].convert_objects(convert_numeric=True)\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.000027\n",
       "1       -0.005933\n",
       "2       -0.000305\n",
       "3       -0.002021\n",
       "4       -0.001442\n",
       "           ...   \n",
       "29851   -0.000314\n",
       "29852    0.000084\n",
       "29853   -0.000097\n",
       "29854   -0.000075\n",
       "29855    0.000152\n",
       "Name: raw_data, Length: 29856, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df['raw_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202011</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29851</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29852</td>\n",
       "      <td>201924</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29853</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29854</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29855</td>\n",
       "      <td>201924</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29856 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       period  raw_data  closer#  category  label  Silhouette\n",
       "0      202011  0.000027        2         3    1.0    0.126229\n",
       "1      202011 -0.005933        2         3   12.0    0.126229\n",
       "2      202011 -0.000305        2         3   13.0    0.126229\n",
       "3      202011 -0.002021        2         3   12.0    0.126229\n",
       "4      202011 -0.001442        2         3   12.0    0.126229\n",
       "...       ...       ...      ...       ...    ...         ...\n",
       "29851  201924 -0.000314        2         3    8.0    0.008477\n",
       "29852  201924  0.000084        2         3   12.0    0.008477\n",
       "29853  201924 -0.000097        2         3    5.0    0.008477\n",
       "29854  201924 -0.000075        2         3    8.0    0.008477\n",
       "29855  201924  0.000152        2         3   11.0    0.008477\n",
       "\n",
       "[29856 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [period, raw_data, closer#, category, label, Silhouette]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df.loc[x_data_df['category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_data_df,y_data_df,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 11 ,n_jobs=-1) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_test)  # random forest predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :   1.0\n",
      "Random Forest Precision :   1.0\n",
      "Random Forest Recall :   1.0\n",
      "Random Forest f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy :  ',accuracy_score(y_test,rf_pred))\n",
    "print('Random Forest Precision :  ',precision_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest Recall :  ',recall_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest f1 :  ',f1_score(y_test,rf_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy :   1.0\n",
      "Decision Tree Precision :   1.0\n",
      "Decision Tree Recall :   1.0\n",
      "Decision Tree f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy :  ',accuracy_score(y_test,dt_pred))\n",
    "print('Decision Tree Precision :  ',precision_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree Recall :  ',recall_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree f1 :  ',f1_score(y_test,dt_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 11) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gredient Boosting Accuracy :   1.0\n",
      "Gredient Boosting Precision :   1.0\n",
      "Gredient Boosting Recall :   1.0\n",
      "Gredient Boosting f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Gredient Boosting Accuracy :  ',accuracy_score(y_test,gb_pred))\n",
    "print('Gredient Boosting Precision :  ',precision_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting Recall :  ',recall_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting f1 :  ',f1_score(y_test,gb_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy :   0.5068653717347622\n",
      "Logistic Regression  Precision :   0.2569125050638187\n",
      "Logistic Regression  Recall :   0.5068653717347622\n",
      "Logistic Regression  f1 :   0.34098932775666746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy :  ',accuracy_score(y_test,lr_pred))\n",
    "print('Logistic Regression  Precision :  ',precision_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  Recall :  ',recall_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  f1 :  ',f1_score(y_test,lr_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.merge(x_data_df,y_data_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/twitter_data_before_analysis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-34b2be433ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/twitter_data_before_analysis.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/twitter_data_before_analysis.csv'"
     ]
    }
   ],
   "source": [
    "data_df.to_csv(\"./data/twitter_data_before_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
