{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,precision_score , recall_score , confusion_matrix , f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from ast import literal_eval\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020U1 = eucl_data\n",
    "data_2020U1.append(cosine_data)\n",
    "\n",
    "data_2020U1['period'] = 202011 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2020_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020D1 = eucl_data\n",
    "data_2020D1.append(cosine_data)\n",
    "\n",
    "data_2020D1['period'] = 202021 # 2020년의 down 2 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U1 = eucl_data\n",
    "data_2017U1.append(cosine_data)\n",
    "\n",
    "data_2017U1['period'] = 201711 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2017_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U2 = eucl_data\n",
    "data_2017U2.append(cosine_data)\n",
    "\n",
    "data_2017U2['period'] = 201712 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D1 = eucl_data\n",
    "data_2018D1.append(cosine_data)\n",
    "\n",
    "data_2018D1['period'] = 201821 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_complement1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_complement1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018C1 = eucl_data\n",
    "data_2018C1.append(cosine_data)\n",
    "\n",
    "data_2018C1['period'] = 201831 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2018_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D2 = eucl_data\n",
    "data_2018D2.append(cosine_data)\n",
    "\n",
    "data_2018D2['period'] = 201822 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U1 = eucl_data\n",
    "data_2019U1.append(cosine_data)\n",
    "\n",
    "data_2019U1['period'] = 201911 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U2 = eucl_data\n",
    "data_2019U2.append(cosine_data)\n",
    "\n",
    "data_2019U2['period'] = 201912 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_up3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U3 = eucl_data\n",
    "data_2019U3.append(cosine_data)\n",
    "\n",
    "data_2019U3['period'] = 201913 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D1 = eucl_data\n",
    "data_2019D1.append(cosine_data)\n",
    "\n",
    "data_2019D1['period'] = 201921 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D2 = eucl_data\n",
    "data_2019D2.append(cosine_data)\n",
    "\n",
    "data_2019D2['period'] = 201922 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D3 = eucl_data\n",
    "data_2019D3.append(cosine_data)\n",
    "\n",
    "data_2019D3['period'] = 201923 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down4_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../analysis/cluster/twitter/twitter_2019_down4_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D4 = eucl_data\n",
    "data_2019D4.append(cosine_data)\n",
    "\n",
    "data_2019D4['period'] = 201924 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.concat([data_2020U1,data_2020D1,data_2017U1,data_2018D1,data_2018C1,data_2018D2,data_2019U1,data_2019U2,data_2019U3,data_2019D1,data_2019D2,data_2019D3,data_2019D4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['period'] = pd.to_numeric(data_train['period'], errors='coerce')\n",
    "data_train['category'] = pd.to_numeric(data_train['category'], errors='coerce')\n",
    "data_train['label'] = pd.to_numeric(data_train['label'], errors='coerce')\n",
    "data_train['Silhouette'] = pd.to_numeric(data_train['Silhouette'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "y_data_df = data_train['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))\n",
    "print(len(x_data_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : np.mean(np.array([i for i in x],dtype=float)) )\n",
    "# x_data_df['raw_data'] = pd.to_numeric(x_data_df['raw_data'],errors='coerce')\n",
    "\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].convert_objects(convert_numeric=True)\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.000027\n",
       "1       -0.005933\n",
       "2       -0.000305\n",
       "3       -0.002021\n",
       "4       -0.001442\n",
       "           ...   \n",
       "29851   -0.000314\n",
       "29852    0.000084\n",
       "29853   -0.000097\n",
       "29854   -0.000075\n",
       "29855    0.000152\n",
       "Name: raw_data, Length: 29856, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df['raw_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202011</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>202011</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29851</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29852</td>\n",
       "      <td>201924</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29853</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29854</td>\n",
       "      <td>201924</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29855</td>\n",
       "      <td>201924</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29856 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       period  raw_data  closer#  category  label  Silhouette\n",
       "0      202011  0.000027        2         3    1.0    0.126229\n",
       "1      202011 -0.005933        2         3   12.0    0.126229\n",
       "2      202011 -0.000305        2         3   13.0    0.126229\n",
       "3      202011 -0.002021        2         3   12.0    0.126229\n",
       "4      202011 -0.001442        2         3   12.0    0.126229\n",
       "...       ...       ...      ...       ...    ...         ...\n",
       "29851  201924 -0.000314        2         3    8.0    0.008477\n",
       "29852  201924  0.000084        2         3   12.0    0.008477\n",
       "29853  201924 -0.000097        2         3    5.0    0.008477\n",
       "29854  201924 -0.000075        2         3    8.0    0.008477\n",
       "29855  201924  0.000152        2         3   11.0    0.008477\n",
       "\n",
       "[29856 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [period, raw_data, closer#, category, label, Silhouette]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df.loc[x_data_df['category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_data_df,y_data_df,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 11 ,n_jobs=-1) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=11, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_test)  # random forest predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :   1.0\n",
      "Random Forest Precision :   1.0\n",
      "Random Forest Recall :   1.0\n",
      "Random Forest f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy :  ',accuracy_score(y_test,rf_pred))\n",
    "print('Random Forest Precision :  ',precision_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest Recall :  ',recall_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest f1 :  ',f1_score(y_test,rf_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy :   1.0\n",
      "Decision Tree Precision :   1.0\n",
      "Decision Tree Recall :   1.0\n",
      "Decision Tree f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy :  ',accuracy_score(y_test,dt_pred))\n",
    "print('Decision Tree Precision :  ',precision_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree Recall :  ',recall_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree f1 :  ',f1_score(y_test,dt_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 11) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gredient Boosting Accuracy :   1.0\n",
      "Gredient Boosting Precision :   1.0\n",
      "Gredient Boosting Recall :   1.0\n",
      "Gredient Boosting f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Gredient Boosting Accuracy :  ',accuracy_score(y_test,gb_pred))\n",
    "print('Gredient Boosting Precision :  ',precision_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting Recall :  ',recall_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting f1 :  ',f1_score(y_test,gb_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy :   0.6311118553248493\n",
      "Logistic Regression  Precision :   0.5724937216508463\n",
      "Logistic Regression  Recall :   0.6311118553248493\n",
      "Logistic Regression  f1 :   0.5758142359673168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy :  ',accuracy_score(y_test,lr_pred))\n",
    "print('Logistic Regression  Precision :  ',precision_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  Recall :  ',recall_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  f1 :  ',f1_score(y_test,lr_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.merge(x_data_df,y_data_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
