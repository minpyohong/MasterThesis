{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,precision_score , recall_score , confusion_matrix , f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from ast import literal_eval\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data_train = pd.read_csv('./data/twitter_data_before_analysis.csv', error_bad_lines=False)\n",
    "data_train = pd.read_csv('./data/twitter_data_before_analysis1.csv', error_bad_lines=False)\n",
    "data_train = data_train.append(pd.read_csv('./data/ko_news_data_before_analysis.csv', error_bad_lines=False))\n",
    "data_train = data_train.append(pd.read_csv('./data/en_news_data_before_analysis.csv', error_bad_lines=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train['period'] = pd.to_numeric(data_train['period'], errors='coerce')\n",
    "data_train['category'] = pd.to_numeric(data_train['category'], errors='coerce')\n",
    "data_train['label'] = pd.to_numeric(data_train['label'], errors='coerce')\n",
    "data_train['Silhouette'] = pd.to_numeric(data_train['Silhouette'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data_df = data_train[data_train.columns.difference(['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "y_data_df = data_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_data_df = x_data_df.drop('Unnamed: 0', axis=1)\n",
    "x_data_df = x_data_df.drop('result', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187533\n"
     ]
    }
   ],
   "source": [
    "#x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))\n",
    "print(len(x_data_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_data_df,y_data_df,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 11 ,n_jobs=-1) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = rf_clf.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_test)  # random forest predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :   0.9494494361052603\n",
      "Random Forest Precision :   0.9497924998185214\n",
      "Random Forest Recall :   0.9494494361052603\n",
      "Random Forest f1 :   0.9482553598673159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy :  ',accuracy_score(y_test,rf_pred))\n",
    "print('Random Forest Precision :  ',precision_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest Recall :  ',recall_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest f1 :  ',f1_score(y_test,rf_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74, 0.01, 0.  , ..., 0.03, 0.  , 0.15],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.96, 0.  , ..., 0.  , 0.01, 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy :   0.9249206814727917\n",
      "Decision Tree Precision :   0.9247613044827593\n",
      "Decision Tree Recall :   0.9249206814727917\n",
      "Decision Tree f1 :   0.9248182373700018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy :  ',accuracy_score(y_test,dt_pred))\n",
    "print('Decision Tree Precision :  ',precision_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree Recall :  ',recall_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree f1 :  ',f1_score(y_test,dt_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#gb_clf = GradientBoostingClassifier(random_state = 11) # random forest\n",
    "lgbm_clf =  LGBMClassifier(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#gb_clf.fit(X_train,y_train)\n",
    "#gb_pred = gb_clf.predict(X_test)\n",
    "\n",
    "lgbm_clf.fit(X_train,y_train)\n",
    "lgbm_pred = lgbm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Accuracy :   0.9520622817074146\n",
      "Light GBM Precision :   0.9518781433763122\n",
      "Light GBM Recall :   0.9520622817074146\n",
      "Light GBM f1 :   0.9516501577413158\n"
     ]
    }
   ],
   "source": [
    "#print('Gredient Boosting Accuracy :  ',accuracy_score(y_test,gb_pred))\n",
    "#print('Gredient Boosting Precision :  ',precision_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "#print('Gredient Boosting Recall :  ',recall_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "#print('Gredient Boosting f1 :  ',f1_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Light GBM Accuracy :  ',accuracy_score(y_test,lgbm_pred))\n",
    "print('Light GBM Precision :  ',precision_score(y_test,lgbm_pred,pos_label='positive',average='weighted'))\n",
    "print('Light GBM Recall :  ',recall_score(y_test,lgbm_pred,pos_label='positive',average='weighted'))\n",
    "print('Light GBM f1 :  ',f1_score(y_test,lgbm_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy :   0.34089636601167783\n",
      "Logistic Regression  Precision :   0.1162103323599678\n",
      "Logistic Regression  Recall :   0.34089636601167783\n",
      "Logistic Regression  f1 :   0.17333231009585082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy :  ',accuracy_score(y_test,lr_pred))\n",
    "print('Logistic Regression  Precision :  ',precision_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  Recall :  ',recall_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  f1 :  ',f1_score(y_test,lr_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(120, input_dim=104, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = y_train.apply(lambda x : x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_cate_train = to_categorical(y_train , num_classes=13)\n",
    "#y_cate_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150026/150026 [==============================] - 1s 7us/step - loss: 202.0133 - accuracy: 0.2819\n",
      "Epoch 2/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 2.2839 - accuracy: 0.3010\n",
      "Epoch 3/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 2.1321 - accuracy: 0.3010\n",
      "Epoch 4/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 2.0303 - accuracy: 0.3010\n",
      "Epoch 5/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.9675 - accuracy: 0.3142\n",
      "Epoch 6/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.9307 - accuracy: 0.3370\n",
      "Epoch 7/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.9095 - accuracy: 0.3370\n",
      "Epoch 8/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8970 - accuracy: 0.3370\n",
      "Epoch 9/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8891 - accuracy: 0.3370\n",
      "Epoch 10/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8836 - accuracy: 0.3370\n",
      "Epoch 11/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8796 - accuracy: 0.3370\n",
      "Epoch 12/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8763 - accuracy: 0.3370\n",
      "Epoch 13/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8737 - accuracy: 0.3370\n",
      "Epoch 14/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8715 - accuracy: 0.3370\n",
      "Epoch 15/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8697 - accuracy: 0.3370\n",
      "Epoch 16/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8682 - accuracy: 0.3370\n",
      "Epoch 17/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8669 - accuracy: 0.3370\n",
      "Epoch 18/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8658 - accuracy: 0.3370\n",
      "Epoch 19/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8649 - accuracy: 0.3370\n",
      "Epoch 20/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8641 - accuracy: 0.3370\n",
      "Epoch 21/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8634 - accuracy: 0.3370\n",
      "Epoch 22/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8629 - accuracy: 0.3370\n",
      "Epoch 23/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8624 - accuracy: 0.3370\n",
      "Epoch 24/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8620 - accuracy: 0.3370\n",
      "Epoch 25/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8617 - accuracy: 0.3370\n",
      "Epoch 26/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8614 - accuracy: 0.3370\n",
      "Epoch 27/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8612 - accuracy: 0.3370\n",
      "Epoch 28/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8610 - accuracy: 0.3370\n",
      "Epoch 29/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8608 - accuracy: 0.3370\n",
      "Epoch 30/30\n",
      "150026/150026 [==============================] - 1s 6us/step - loss: 1.8607 - accuracy: 0.3370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb419f2fcd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_cate_train, epochs=30, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test = y_test.apply(lambda x : x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_cate_test = to_categorical(y_test , num_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37507/37507 [==============================] - 0s 3us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_cate_test, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6101310421848596, 0.2952515482902527]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test ,batch_size=500 )\n",
    "\n",
    "yhat_classes = model.predict_classes(X_test ,batch_size=500 )\n",
    "\n",
    "# reduce to 1d array\n",
    "#yhat_probs = yhat_probs[:, 0]\n",
    "#yhat_classes = yhat_classes[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.295252\n",
      "Precision: 0.295252\n",
      "Recall: 0.295252\n",
      "F1 score: 0.295252\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_classes )\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_classes , average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_classes , average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, yhat_classes,average='micro')\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
