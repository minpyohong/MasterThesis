{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,precision_score , recall_score , confusion_matrix , f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from ast import literal_eval\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2020_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2020_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020U1 = eucl_data\n",
    "data_2020U1.append(cosine_data)\n",
    "\n",
    "data_2020U1['period'] = 202011 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2020_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2020_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020D1 = eucl_data\n",
    "data_2020D1.append(cosine_data)\n",
    "\n",
    "data_2020D1['period'] = 202021 # 2020년의 down 2 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2017_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2017_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U1 = eucl_data\n",
    "data_2017U1.append(cosine_data)\n",
    "\n",
    "data_2017U1['period'] = 201711 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2017_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2017_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2017U2 = eucl_data\n",
    "data_2017U2.append(cosine_data)\n",
    "\n",
    "data_2017U2['period'] = 201712 # 2020년의 up 1 , 첫번째 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D1 = eucl_data\n",
    "data_2018D1.append(cosine_data)\n",
    "\n",
    "data_2018D1['period'] = 201821 # 2020년의 up 1 , 첫번째 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_complement1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_complement1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018C1 = eucl_data\n",
    "data_2018C1.append(cosine_data)\n",
    "\n",
    "data_2018C1['period'] = 201831 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2018_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2018D2 = eucl_data\n",
    "data_2018D2.append(cosine_data)\n",
    "\n",
    "data_2018D2['period'] = 201822 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U1 = eucl_data\n",
    "data_2019U1.append(cosine_data)\n",
    "\n",
    "data_2019U1['period'] = 201911 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U2 = eucl_data\n",
    "data_2019U2.append(cosine_data)\n",
    "\n",
    "data_2019U2['period'] = 201912 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_up3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019U3 = eucl_data\n",
    "data_2019U3.append(cosine_data)\n",
    "\n",
    "data_2019U3['period'] = 201913 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down1_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down1_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D1 = eucl_data\n",
    "data_2019D1.append(cosine_data)\n",
    "\n",
    "data_2019D1['period'] = 201921 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D2 = eucl_data\n",
    "data_2019D2.append(cosine_data)\n",
    "\n",
    "data_2019D2['period'] = 201922 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down3_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down3_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D3 = eucl_data\n",
    "data_2019D3.append(cosine_data)\n",
    "\n",
    "data_2019D3['period'] = 201923 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down4_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/twitter/twitter_2019_down4_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2019D4 = eucl_data\n",
    "data_2019D4.append(cosine_data)\n",
    "\n",
    "data_2019D4['period'] = 201924 # 2020년의 up 1 , down 2 , complement 3 첫번째 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.concat([data_2020U1,data_2020D1,data_2017U1,data_2018D1,data_2018C1,data_2018D2,data_2019U1,data_2019U2,data_2019U3,data_2019D1,data_2019D2,data_2019D3,data_2019D4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['period'] = pd.to_numeric(data_train['period'], errors='coerce')\n",
    "data_train['category'] = pd.to_numeric(data_train['category'], errors='coerce')\n",
    "data_train['label'] = pd.to_numeric(data_train['label'], errors='coerce')\n",
    "data_train['Silhouette'] = pd.to_numeric(data_train['Silhouette'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "y_data_df = data_train['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "for i in range(1,101) :\n",
    "    header.append('C'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))\n",
    "print(len(x_data_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFrame = pd.DataFrame(columns = header )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n"
     ]
    }
   ],
   "source": [
    "for index,row in x_data_df.iterrows() :\n",
    "\n",
    "    raw_data_list = [float(i.replace(\" \",\"\")) for i in row['raw_data']]\n",
    "    #print(raw_data_list)\n",
    "    #print(len(raw_data_list))\n",
    "    #print(len(header))\n",
    "    \n",
    "    \n",
    "    tempSeries = pd.Series(raw_data_list , index = header)\n",
    "    \n",
    "    tempFrame = tempFrame.append(tempSeries , ignore_index=True)\n",
    "    \n",
    "    if( (index%1000)==0 ) :\n",
    "        print(index)\n",
    "    \n",
    "    #for k in range(0,len(raw_data_list1)) :\n",
    "    #    col = 'C'+str(k+1)\n",
    "        #print(col)\n",
    "        #row(col) = raw_data_list1[k]\n",
    "    #    x_data_df.loc[index,col] = raw_data_list1[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = pd.concat([x_data_df,tempFrame],axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : np.mean(np.array([i for i in x],dtype=float)) )\n",
    "# x_data_df['raw_data'] = pd.to_numeric(x_data_df['raw_data'],errors='coerce')\n",
    "\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].convert_objects(convert_numeric=True)\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['raw_data'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e4538a8b152e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3963\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3964\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3965\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3967\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['raw_data'] not found in axis\""
     ]
    }
   ],
   "source": [
    "x_data_df = x_data_df.drop('raw_data',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>...</th>\n",
       "      <th>C91</th>\n",
       "      <th>C92</th>\n",
       "      <th>C93</th>\n",
       "      <th>C94</th>\n",
       "      <th>C95</th>\n",
       "      <th>C96</th>\n",
       "      <th>C97</th>\n",
       "      <th>C98</th>\n",
       "      <th>C99</th>\n",
       "      <th>C100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [period, closer#, category, label, Silhouette, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, C21, C22, C23, C24, C25, C26, C27, C28, C29, C30, C31, C32, C33, C34, C35, C36, C37, C38, C39, C40, C41, C42, C43, C44, C45, C46, C47, C48, C49, C50, C51, C52, C53, C54, C55, C56, C57, C58, C59, C60, C61, C62, C63, C64, C65, C66, C67, C68, C69, C70, C71, C72, C73, C74, C75, C76, C77, C78, C79, C80, C81, C82, C83, C84, C85, C86, C87, C88, C89, C90, C91, C92, C93, C94, C95, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 205 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df.loc[x_data_df['category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_data_df,y_data_df,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 11 ,n_jobs=-1) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_test)  # random forest predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :   1.0\n",
      "Random Forest Precision :   1.0\n",
      "Random Forest Recall :   1.0\n",
      "Random Forest f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy :  ',accuracy_score(y_test,rf_pred))\n",
    "print('Random Forest Precision :  ',precision_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest Recall :  ',recall_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest f1 :  ',f1_score(y_test,rf_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy :   1.0\n",
      "Decision Tree Precision :   1.0\n",
      "Decision Tree Recall :   1.0\n",
      "Decision Tree f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy :  ',accuracy_score(y_test,dt_pred))\n",
    "print('Decision Tree Precision :  ',precision_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree Recall :  ',recall_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree f1 :  ',f1_score(y_test,dt_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 11) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gredient Boosting Accuracy :   1.0\n",
      "Gredient Boosting Precision :   1.0\n",
      "Gredient Boosting Recall :   1.0\n",
      "Gredient Boosting f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Gredient Boosting Accuracy :  ',accuracy_score(y_test,gb_pred))\n",
    "print('Gredient Boosting Precision :  ',precision_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting Recall :  ',recall_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting f1 :  ',f1_score(y_test,gb_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy :   0.5068653717347622\n",
      "Logistic Regression  Precision :   0.2569125050638187\n",
      "Logistic Regression  Recall :   0.5068653717347622\n",
      "Logistic Regression  f1 :   0.34098932775666746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1270: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy :  ',accuracy_score(y_test,lr_pred))\n",
    "print('Logistic Regression  Precision :  ',precision_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  Recall :  ',recall_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  f1 :  ',f1_score(y_test,lr_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data_df.to_csv('./data/twitter_data_before_analysis1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.merge(x_data_df,y_data_df,left_index=True,right_index=True)\n",
    "data_df.to_csv(\"./data/ko_news_data_before_analysis1.csv\")\n",
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv(\"./testdata/twitter_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
