{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score ,precision_score , recall_score , confusion_matrix , f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from ast import literal_eval\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/ko_news/2020_up2/(test)_ko_news_2020_up2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/ko_news/2020_up2/(test)_ko_news_2020_up2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020U2 = eucl_data\n",
    "data_2020U2.append(cosine_data)\n",
    "\n",
    "data_2020U2['period'] = 202012 # 2020년의 up 1 , 첫번째 1\n",
    "data_2020U2['result'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_data = pd.read_csv('../../analysis/cluster/ko_news/2020_down2/(test)_ko_news_2020_down2_euclidean.csv', error_bad_lines=False)\n",
    "eucl_data['closer#'] = 2 # cosine 1 , euclidean 2\n",
    "\n",
    "cosine_data = pd.read_csv('../../analysis/cluster/ko_news/2020_down2/(test)_ko_news_2020_down2_cosine.csv', error_bad_lines=False)\n",
    "cosine_data['closer#'] = 1 # cosine 1 , euclidean 2\n",
    "\n",
    "data_2020D2 = eucl_data\n",
    "data_2020D2.append(cosine_data)\n",
    "\n",
    "data_2020D2['period'] = 202022 # 2020년의 down 2 , 첫번째 1\n",
    "data_2020D2['result'] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.concat([data_2020U2,data_2020D2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['period'] = pd.to_numeric(data_train['period'], errors='coerce')\n",
    "data_train['category'] = pd.to_numeric(data_train['category'], errors='coerce')\n",
    "data_train['label'] = pd.to_numeric(data_train['label'], errors='coerce')\n",
    "data_train['Silhouette'] = pd.to_numeric(data_train['Silhouette'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "for i in range(1,101) :\n",
    "    header.append('C'+str(i))\n",
    "\n",
    "#header.append('period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data_df[['period','raw_data','closer#','category','label','Silhouette']] = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>closer#</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202012</td>\n",
       "      <td>[-0.004228988662362099, 0.0032927740830928087,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.527766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>202012</td>\n",
       "      <td>[-0.0003981642075814307, -0.002887157257646322...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.527766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>202012</td>\n",
       "      <td>[-0.004501998890191317, 0.0025414619594812393,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.527766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>202012</td>\n",
       "      <td>[-0.0022405448835343122, -0.001110535347834229...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.527766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>202012</td>\n",
       "      <td>[-0.01843189261853695, 0.006984345614910126, 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4822</td>\n",
       "      <td>202022</td>\n",
       "      <td>[-0.004609350115060806, 0.0036972039379179478,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4823</td>\n",
       "      <td>202022</td>\n",
       "      <td>[-0.004539160057902336, -0.00488355103880167, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4824</td>\n",
       "      <td>202022</td>\n",
       "      <td>[0.004244538024067879, -0.0033438359387218952,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>202022</td>\n",
       "      <td>[-0.0006792934727855027, -0.000359244673745706...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4826</td>\n",
       "      <td>202022</td>\n",
       "      <td>[-0.002238636137917638, -0.001959411194548011,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4827 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      period                                           raw_data  closer#  \\\n",
       "0     202012  [-0.004228988662362099, 0.0032927740830928087,...        2   \n",
       "1     202012  [-0.0003981642075814307, -0.002887157257646322...        2   \n",
       "2     202012  [-0.004501998890191317, 0.0025414619594812393,...        2   \n",
       "3     202012  [-0.0022405448835343122, -0.001110535347834229...        2   \n",
       "4     202012  [-0.01843189261853695, 0.006984345614910126, 0...        2   \n",
       "...      ...                                                ...      ...   \n",
       "4822  202022  [-0.004609350115060806, 0.0036972039379179478,...        2   \n",
       "4823  202022  [-0.004539160057902336, -0.00488355103880167, ...        2   \n",
       "4824  202022  [0.004244538024067879, -0.0033438359387218952,...        2   \n",
       "4825  202022  [-0.0006792934727855027, -0.000359244673745706...        2   \n",
       "4826  202022  [-0.002238636137917638, -0.001959411194548011,...        2   \n",
       "\n",
       "      category  label  Silhouette  \n",
       "0            2    6.0    0.527766  \n",
       "1            2    6.0    0.527766  \n",
       "2            2    7.0    0.527766  \n",
       "3            2    6.0    0.527766  \n",
       "4            2    1.0    0.527766  \n",
       "...        ...    ...         ...  \n",
       "4822         2    7.0    0.009394  \n",
       "4823         2   12.0    0.009394  \n",
       "4824         2   12.0    0.009394  \n",
       "4825         2   12.0    0.009394  \n",
       "4826         2   12.0    0.009394  \n",
       "\n",
       "[4827 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data_df = data_train[['period','raw_data','closer#','category','label','Silhouette']]\n",
    "y_data_df = data_train['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x: x[1:len(x)-1].split(','))\n",
    "print(len(x_data_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_data_df['category'] = x_data_df['category'].fillna(2)\n",
    "x_data_df['Silhouette'] = x_data_df['Silhouette'].fillna(0.009903253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_list1 = [float(i.replace(\" \",\"\")) for i in raw_data_list]\n",
    "# len(raw_data_list1)\n",
    "\n",
    "tempFrame = pd.DataFrame(columns = header )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>C91</th>\n",
       "      <th>C92</th>\n",
       "      <th>C93</th>\n",
       "      <th>C94</th>\n",
       "      <th>C95</th>\n",
       "      <th>C96</th>\n",
       "      <th>C97</th>\n",
       "      <th>C98</th>\n",
       "      <th>C99</th>\n",
       "      <th>C100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, C21, C22, C23, C24, C25, C26, C27, C28, C29, C30, C31, C32, C33, C34, C35, C36, C37, C38, C39, C40, C41, C42, C43, C44, C45, C46, C47, C48, C49, C50, C51, C52, C53, C54, C55, C56, C57, C58, C59, C60, C61, C62, C63, C64, C65, C66, C67, C68, C69, C70, C71, C72, C73, C74, C75, C76, C77, C78, C79, C80, C81, C82, C83, C84, C85, C86, C87, C88, C89, C90, C91, C92, C93, C94, C95, C96, C97, C98, C99, C100]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "for index,row in x_data_df.iterrows() :\n",
    "\n",
    "    raw_data_list = [float(i.replace(\" \",\"\")) for i in row['raw_data']]\n",
    "    \n",
    "    \n",
    "    tempSeries = pd.Series(raw_data_list , index = header)\n",
    "    \n",
    "    tempFrame = tempFrame.append(tempSeries , ignore_index=True)\n",
    "    \n",
    "    if( (index%1000)==0 ) :\n",
    "        print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>C91</th>\n",
       "      <th>C92</th>\n",
       "      <th>C93</th>\n",
       "      <th>C94</th>\n",
       "      <th>C95</th>\n",
       "      <th>C96</th>\n",
       "      <th>C97</th>\n",
       "      <th>C98</th>\n",
       "      <th>C99</th>\n",
       "      <th>C100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.004229</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.002224</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.003239</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.004377</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>-0.002989</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>-0.004734</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002862</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>-0.004218</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>-0.002392</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.009090</td>\n",
       "      <td>-0.005909</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>-0.011997</td>\n",
       "      <td>-0.010243</td>\n",
       "      <td>-0.006984</td>\n",
       "      <td>-0.007337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>-0.013348</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>-0.007265</td>\n",
       "      <td>0.008134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.001244</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.004066</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.002397</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.018432</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>-0.018984</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>-0.028526</td>\n",
       "      <td>-0.040351</td>\n",
       "      <td>-0.026151</td>\n",
       "      <td>-0.008185</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.066159</td>\n",
       "      <td>0.031454</td>\n",
       "      <td>-0.016547</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.032120</td>\n",
       "      <td>-0.003801</td>\n",
       "      <td>-0.008890</td>\n",
       "      <td>0.026624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4822</td>\n",
       "      <td>-0.004609</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>-0.004835</td>\n",
       "      <td>-0.003212</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>0.002134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4823</td>\n",
       "      <td>-0.004539</td>\n",
       "      <td>-0.004884</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>-0.002239</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>-0.003588</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>-0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4824</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>-0.004914</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.004663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.004753</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4826</td>\n",
       "      <td>-0.002239</td>\n",
       "      <td>-0.001959</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.001317</td>\n",
       "      <td>-0.004277</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4827 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            C1        C2        C3        C4        C5        C6        C7  \\\n",
       "0    -0.004229  0.003293  0.006054 -0.002224  0.001972  0.000346 -0.002963   \n",
       "1    -0.000398 -0.002887  0.002996  0.002652 -0.002989  0.003932 -0.000892   \n",
       "2    -0.004502  0.002541  0.010471 -0.009090 -0.005909 -0.013358 -0.011997   \n",
       "3    -0.002241 -0.001111 -0.001244 -0.001471  0.001443 -0.000429 -0.004066   \n",
       "4    -0.018432  0.006984  0.011238 -0.018984 -0.008792 -0.028526 -0.040351   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4822 -0.004609  0.003697 -0.001580  0.003537  0.003832 -0.000864  0.003708   \n",
       "4823 -0.004539 -0.004884  0.003570 -0.003763 -0.000241  0.004238  0.000715   \n",
       "4824  0.004245 -0.003344  0.000961  0.001370 -0.001678 -0.004914 -0.000472   \n",
       "4825 -0.000679 -0.000359 -0.004753  0.004594 -0.002525  0.004997 -0.004576   \n",
       "4826 -0.002239 -0.001959  0.003870  0.001909  0.001979  0.002889  0.002266   \n",
       "\n",
       "            C8        C9       C10  ...       C91       C92       C93  \\\n",
       "0    -0.004496 -0.003239 -0.000382  ...  0.002087  0.010243  0.002303   \n",
       "1     0.003515 -0.004734 -0.004943  ... -0.002862  0.003644  0.003140   \n",
       "2    -0.010243 -0.006984 -0.007337  ...  0.006648  0.031064  0.009251   \n",
       "3    -0.000293  0.002474 -0.000441  ...  0.005339  0.006415 -0.002328   \n",
       "4    -0.026151 -0.008185 -0.024971  ...  0.019615  0.066159  0.031454   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4822 -0.001852 -0.004692 -0.000712  ...  0.004796  0.000966 -0.000437   \n",
       "4823  0.000708 -0.000802 -0.001468  ... -0.004227 -0.002239 -0.002863   \n",
       "4824  0.004364 -0.004543  0.003035  ...  0.000193  0.002290  0.004925   \n",
       "4825 -0.001308  0.003555  0.004234  ...  0.000594  0.002078 -0.003228   \n",
       "4826 -0.004528  0.004529  0.002229  ...  0.000201 -0.000532 -0.001317   \n",
       "\n",
       "           C94       C95       C96       C97       C98       C99      C100  \n",
       "0    -0.000316 -0.000294 -0.000768 -0.004377 -0.003873  0.001513  0.000277  \n",
       "1    -0.004218 -0.001059 -0.002392 -0.002752  0.003818  0.002272  0.001947  \n",
       "2    -0.005638  0.002786 -0.001285 -0.013348  0.002910 -0.007265  0.008134  \n",
       "3    -0.002838  0.001714  0.002930 -0.002405 -0.002397  0.002360  0.000143  \n",
       "4    -0.016547 -0.000211 -0.011558 -0.032120 -0.003801 -0.008890  0.026624  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4822 -0.000030  0.003463 -0.004835 -0.003212 -0.000214 -0.002266  0.002134  \n",
       "4823 -0.000813  0.001827 -0.003588 -0.001499 -0.000477 -0.003620 -0.000130  \n",
       "4824  0.003585  0.000956 -0.000193  0.001932  0.002314 -0.002046 -0.004663  \n",
       "4825  0.000956 -0.005007  0.003714  0.001492 -0.000312  0.000524 -0.002146  \n",
       "4826 -0.004277 -0.002252  0.001215 -0.003881 -0.001821 -0.001259 -0.000039  \n",
       "\n",
       "[4827 rows x 100 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = pd.concat([x_data_df,tempFrame],axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_df = x_data_df.drop('raw_data',axis=1)\n",
    "#x_data_df['raw_data'] = x_data_df['raw_data'].apply(lambda x : np.mean(np.array([i for i in x],dtype=float)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3968"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_data_df,y_data_df,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state = 11 ,n_jobs=-1) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bac9269f2616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[1;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 304\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0;32m--> 806\u001b[0;31m                         ensure_2d=False, dtype=None)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 646\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n\u001b[0;32m--> 100\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "rf_clf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(X_test)  # random forest predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :   0.9998899042166685\n",
      "Random Forest Precision :   0.9998899300123065\n",
      "Random Forest Recall :   0.9998899042166685\n",
      "Random Forest f1 :   0.9998899035734472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy :  ',accuracy_score(y_test,rf_pred))\n",
    "print('Random Forest Precision :  ',precision_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest Recall :  ',recall_score(y_test,rf_pred,pos_label='positive',average='weighted'))\n",
    "print('Random Forest f1 :  ',f1_score(y_test,rf_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 11)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy :   1.0\n",
      "Decision Tree Precision :   1.0\n",
      "Decision Tree Recall :   1.0\n",
      "Decision Tree f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Accuracy :  ',accuracy_score(y_test,dt_pred))\n",
    "print('Decision Tree Precision :  ',precision_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree Recall :  ',recall_score(y_test,dt_pred,pos_label='positive',average='weighted'))\n",
    "print('Decision Tree f1 :  ',f1_score(y_test,dt_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 11) # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gredient Boosting Accuracy :   1.0\n",
      "Gredient Boosting Precision :   1.0\n",
      "Gredient Boosting Recall :   1.0\n",
      "Gredient Boosting f1 :   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Gredient Boosting Accuracy :  ',accuracy_score(y_test,gb_pred))\n",
    "print('Gredient Boosting Precision :  ',precision_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting Recall :  ',recall_score(y_test,gb_pred,pos_label='positive',average='weighted'))\n",
    "print('Gredient Boosting f1 :  ',f1_score(y_test,gb_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy :   0.4697787074755037\n",
      "Logistic Regression  Precision :   0.22069203399735488\n",
      "Logistic Regression  Recall :   0.4697787074755037\n",
      "Logistic Regression  f1 :   0.3003064786214193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/hongminpyo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy :  ',accuracy_score(y_test,lr_pred))\n",
    "print('Logistic Regression  Precision :  ',precision_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  Recall :  ',recall_score(y_test,lr_pred,pos_label='positive',average='weighted'))\n",
    "print('Logistic Regression  f1 :  ',f1_score(y_test,lr_pred,pos_label='positive',average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_df.to_csv(\"./testdata/en_news_analysis.csv\")\n",
    "data_df = pd.merge(x_data_df,y_data_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"./data/ko_news_data_before_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
